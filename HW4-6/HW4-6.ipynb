{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 小說爬蟲"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import types\n",
    "r = requests.get(\"https://8book.com/books/novelbook_98524.html\")\n",
    "\n",
    "soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "\n",
    "#print(soup)\n",
    "link = []\n",
    "for table in soup.find_all(\"table\", {'class' : 'episodelist'}):\n",
    "    for tr in table.find_all('tr'):\n",
    "        for a in tr.find_all('a', href=True):\n",
    "            link.append('https://8book.com' + a['href'])\n",
    "novel=''\n",
    "for i in range(len(link)):\n",
    "    r = requests.get(link[i])\n",
    "    r.encoding = 'big5'\n",
    "    soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "    st = soup.find('p')\n",
    "    \n",
    "    for s in st:\n",
    "        novel += str(s).replace('(adsbygoogle = window.adsbygoogle || []).push({});', '')\n",
    "f = open('novel/novel_1.txt','wb')\n",
    "#f.write(novel.encode('utf-8'))\n",
    "f.write(novel.replace('<br/>', '').encode('utf-8'))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 切開字詞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba \n",
    "import codecs\n",
    "import os\n",
    "from argparse import ArgumentParser\n",
    "\n",
    "def main():\n",
    "    f = codecs.open('novel/novel_{0}.txt'.format(2), 'r', 'utf-8')\n",
    "    textseg=[]\n",
    "    text = ''\n",
    "    jieba.load_userdict(\"dict/user_dict_{0}\".format(1))\n",
    "    seg = jieba.cut(f.readlines()[0],cut_all=False)\n",
    "    for s in seg:\n",
    "        textseg.append(s)\n",
    "    fileseg ='segphase/segphases_{0}.txt'.format(2)\n",
    "    try:\n",
    "        os.path.isfile(fileseg)\n",
    "    except:\n",
    "        open(fileseg,'wb')\n",
    "    with open(fileseg,'wb') as fW:\n",
    "        for i in range(len(textseg)):\n",
    "            fW.write(textseg[i].encode('utf-8'))\n",
    "            fW.write('\\n'.encode('utf-8'))\n",
    "\n",
    "\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## word to vector + 文字雲"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-06 00:57:57,086 : INFO : loading Word2Vec object from word2vec/word2vec_2.model\n",
      "2019-06-06 00:57:57,087 : WARNING : this function is deprecated, use smart_open.open instead\n",
      "2019-06-06 00:57:57,160 : INFO : loading wv recursively from word2vec/word2vec_2.model.wv.* with mmap=None\n",
      "2019-06-06 00:57:57,161 : INFO : setting ignored attribute vectors_norm to None\n",
      "2019-06-06 00:57:57,161 : INFO : loading vocabulary recursively from word2vec/word2vec_2.model.vocabulary.* with mmap=None\n",
      "2019-06-06 00:57:57,162 : INFO : loading trainables recursively from word2vec/word2vec_2.model.trainables.* with mmap=None\n",
      "2019-06-06 00:57:57,163 : INFO : setting ignored attribute cum_table to None\n",
      "2019-06-06 00:57:57,164 : INFO : loaded word2vec/word2vec_2.model\n",
      "F:\\Anaconda\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:21: DeprecationWarning: Call to deprecated `similar_by_vector` (Method will be removed in 4.0.0, use self.wv.similar_by_vector() instead).\n",
      "2019-06-06 00:57:57,171 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-43-dcfc39503b0a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[1;31m#args = parser.parse_args()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m     \u001b[1;31m#main()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 71\u001b[1;33m     \u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-43-dcfc39503b0a>\u001b[0m in \u001b[0;36mtest\u001b[1;34m()\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;31m#phase = input(\"Please input a phase: \")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0mphase\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m     \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msimilar_by_vector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mphase\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtopn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m     \u001b[0mword\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[1;31m# for i in range(args.topn):\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda\\envs\\py36\\lib\\site-packages\\gensim\\utils.py\u001b[0m in \u001b[0;36mnew_func1\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1396\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1397\u001b[0m                 )\n\u001b[1;32m-> 1398\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1399\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1400\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mnew_func1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda\\envs\\py36\\lib\\site-packages\\gensim\\models\\base_any2vec.py\u001b[0m in \u001b[0;36msimilar_by_vector\u001b[1;34m(self, vector, topn, restrict_vocab)\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[0mRefer\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdocumentation\u001b[0m \u001b[1;32mfor\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mgensim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeyedvectors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mWordEmbeddingsKeyedVectors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msimilar_by_vector\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    727\u001b[0m         \"\"\"\n\u001b[1;32m--> 728\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msimilar_by_vector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvector\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtopn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrestrict_vocab\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    729\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    730\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mdeprecated\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Method will be removed in 4.0.0, use self.wv.doesnt_match() instead\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda\\envs\\py36\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36msimilar_by_vector\u001b[1;34m(self, vector, topn, restrict_vocab)\u001b[0m\n\u001b[0;32m    436\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    437\u001b[0m         \"\"\"\n\u001b[1;32m--> 438\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpositive\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvector\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtopn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtopn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrestrict_vocab\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrestrict_vocab\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    439\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    440\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0msimilarity_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtfidf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexponent\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnonzero_limit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mREAL\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda\\envs\\py36\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36mmost_similar\u001b[1;34m(self, positive, negative, topn, restrict_vocab, indexer)\u001b[0m\n\u001b[0;32m    359\u001b[0m         \u001b[1;31m# compute the weighted average of all words\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    360\u001b[0m         \u001b[0mall_words\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmean\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 361\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpositive\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnegative\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    362\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    363\u001b[0m                 \u001b[0mmean\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 0)"
     ]
    }
   ],
   "source": [
    "from gensim.models import word2vec\n",
    "import jieba\n",
    "import logging\n",
    "from argparse import ArgumentParser\n",
    "from sklearn.decomposition import PCA\n",
    "from matplotlib import pyplot\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "def main():\n",
    "\n",
    "    logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "    sentences = word2vec.LineSentence('segphase/segphases_{0}.txt'.format(2))\n",
    "    model = word2vec.Word2Vec(sentences, size=100, alpha=0.0005,min_alpha=0.00001, min_count=20, iter=10)\n",
    "    model.save(\"word2vec/word2vec_{0}.model\".format(2))\n",
    "def test():\n",
    "    model = word2vec.Word2Vec.load('word2vec/word2vec_{0}.model'.format(2))\n",
    "    phase = input(\"Please input a phase: \")\n",
    "    out = model.similar_by_vector(phase,topn=10)\n",
    "    word = []\n",
    "    # for i in range(args.topn):\n",
    "    #     word.append(\" \".join(out[i][0]))\n",
    "    try :\n",
    "        os.path.isfile('tags.txt')\n",
    "    except :\n",
    "        open('tags.txt','wb')\n",
    "    f = open('tags.txt', 'wb')\n",
    "    for i in range(10):\n",
    "        f.write(out[i][0]+\" \")\n",
    "        print(out[i][0])\n",
    "    f.close()\n",
    "    # phase2 = input(\"Please input another phase\")\n",
    "    # print(model.similarity(phase, phase2))\n",
    "    # X = model[model.wv.vocab]\n",
    "    # pca = PCA(n_components=2)\n",
    "    # result = pca.fit_transform(X)\n",
    "\n",
    "    # pyplot.scatter(result[:, 0], result[:, 1])\n",
    "    # words = list(model.wv.vocab)\n",
    "    # for i, word in enumerate(words):\n",
    "    #     pyplot.annotate(word.encode('utf-8'), xy=(result[i, 0], result[i, 1]))\n",
    "    # pyplot.show()\n",
    "\n",
    "    # 讀取每首歌的前10個tags\n",
    "\n",
    "    text = open('tags.txt').read()\n",
    "    print(text)\n",
    "    # 設定停用字(排除常用詞、無法代表特殊意義的字詞)\n",
    "    # stopwords = {}.fromkeys([\"書\"])\n",
    "    # 產生文字雲\n",
    "    wc = WordCloud(font_path=\"NotoSerifCJKtc-Black.otf\", #設置字體\n",
    "               background_color=\"white\", #背景顏色\n",
    "               max_words = 2000 ,)      #停用字詞\n",
    "    wc.generate(text)\n",
    "    # 視覺化呈現\n",
    "    plt.imshow(wc)\n",
    "    plt.axis(\"off\")\n",
    "    # plt.figure(figsize=(10,6), dpi = 100)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    #parser = ArgumentParser()\n",
    "    #parser.add_argument(\"-n\", \"--novel\", default=1,type=int)\n",
    "    #parser.add_argument(\"-m\", \"--mode\", default='train', type=str)\n",
    "    #parser.add_argument(\"-t\", \"--topn\", default=10, type=int)\n",
    "    #args = parser.parse_args()\n",
    "    #main()\n",
    "    test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
