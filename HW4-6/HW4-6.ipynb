{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 小說爬蟲"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import types\n",
    "r = requests.get(\"https://8book.com/books/novelbook_98524.html\")\n",
    "\n",
    "soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "\n",
    "#print(soup)\n",
    "link = []\n",
    "for table in soup.find_all(\"table\", {'class' : 'episodelist'}):\n",
    "    for tr in table.find_all('tr'):\n",
    "        for a in tr.find_all('a', href=True):\n",
    "            link.append('https://8book.com' + a['href'])\n",
    "novel=''\n",
    "for i in range(len(link)):\n",
    "    r = requests.get(link[i])\n",
    "    r.encoding = 'big5'\n",
    "    soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "    st = soup.find('p')\n",
    "    \n",
    "    for s in st:\n",
    "        novel += str(s).replace('(adsbygoogle = window.adsbygoogle || []).push({});', '')\n",
    "f = open('novel/novel_1.txt','wb')\n",
    "#f.write(novel.encode('utf-8'))\n",
    "f.write(novel.replace('<br/>', '').encode('utf-8'))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 切開字詞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\user\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.750 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "import jieba \n",
    "import codecs\n",
    "import os\n",
    "from argparse import ArgumentParser\n",
    "\n",
    "def main():\n",
    "    f = codecs.open('novel/novel_{0}.txt'.format(2), 'r', 'utf-8')\n",
    "    textseg=[]\n",
    "    text = ''\n",
    "    jieba.load_userdict(\"dict/user_dict_{0}\".format(1))\n",
    "    seg = jieba.cut(f.readlines()[0],cut_all=False)\n",
    "    for s in seg:\n",
    "        textseg.append(s)\n",
    "    fileseg ='segphase/segphases_{0}.txt'.format(2)\n",
    "    try:\n",
    "        os.path.isfile(fileseg)\n",
    "    except:\n",
    "        open(fileseg,'wb')\n",
    "    with open(fileseg,'wb') as fW:\n",
    "        for i in range(len(textseg)):\n",
    "            fW.write(textseg[i].encode('utf-8'))\n",
    "            fW.write('\\n'.encode('utf-8'))\n",
    "\n",
    "\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## word to vector + 文字雲"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda\\envs\\py36\\lib\\site-packages\\smart_open\\ssh.py:34: UserWarning: paramiko missing, opening SSH/SCP/SFTP paths will be disabled.  `pip install paramiko` to suppress\n",
      "  warnings.warn('paramiko missing, opening SSH/SCP/SFTP paths will be disabled.  `pip install paramiko` to suppress')\n",
      "F:\\Anaconda\\envs\\py36\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-383aae6af976>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[1;31m#args = parser.parse_args()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[1;31m#main()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m     \u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-3-383aae6af976>\u001b[0m in \u001b[0;36mtest\u001b[1;34m()\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mword2vec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mWord2Vec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'word2vec/word2vec_{0}.model'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;31m#phase = input(\"Please input a phase: \")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m     \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msimilar_by_vector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'郭靖'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtopn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m     \u001b[0mword\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;31m# for i in range(args.topn):\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda\\envs\\py36\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36msimilar_by_vector\u001b[1;34m(self, vector, topn, restrict_vocab)\u001b[0m\n\u001b[0;32m    436\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    437\u001b[0m         \"\"\"\n\u001b[1;32m--> 438\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpositive\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvector\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtopn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtopn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrestrict_vocab\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrestrict_vocab\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    439\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    440\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0msimilarity_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtfidf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexponent\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnonzero_limit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mREAL\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda\\envs\\py36\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36mmost_similar\u001b[1;34m(self, positive, negative, topn, restrict_vocab, indexer)\u001b[0m\n\u001b[0;32m    359\u001b[0m         \u001b[1;31m# compute the weighted average of all words\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    360\u001b[0m         \u001b[0mall_words\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmean\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 361\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpositive\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnegative\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    362\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    363\u001b[0m                 \u001b[0mmean\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 1)"
     ]
    }
   ],
   "source": [
    "from gensim.models import word2vec\n",
    "import jieba\n",
    "import logging\n",
    "from argparse import ArgumentParser\n",
    "from sklearn.decomposition import PCA\n",
    "from matplotlib import pyplot\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "def main():\n",
    "\n",
    "    logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "    sentences = word2vec.LineSentence('segphase/segphases_{0}.txt'.format(2))\n",
    "    model = word2vec.Word2Vec(sentences, size=100, alpha=0.0005,min_alpha=0.00001, min_count=20, iter=10)\n",
    "    model.save(\"word2vec/word2vec_{0}.model\".format(2))\n",
    "def test():\n",
    "    model = word2vec.Word2Vec.load('word2vec/word2vec_{0}.model'.format(2))\n",
    "    #phase = input(\"Please input a phase: \")\n",
    "    out = model.wv.similar_by_vector(['郭靖'],topn=10)\n",
    "    word = []\n",
    "    # for i in range(args.topn):\n",
    "    #     word.append(\" \".join(out[i][0]))\n",
    "    try :\n",
    "        os.path.isfile('tags.txt')\n",
    "    except :\n",
    "        open('tags.txt','wb')\n",
    "    f = open('tags.txt', 'wb')\n",
    "    for i in range(10):\n",
    "        f.write(out[i][0]+\" \")\n",
    "        print(out[i][0])\n",
    "    f.close()\n",
    "    # phase2 = input(\"Please input another phase\")\n",
    "    # print(model.similarity(phase, phase2))\n",
    "    # X = model[model.wv.vocab]\n",
    "    # pca = PCA(n_components=2)\n",
    "    # result = pca.fit_transform(X)\n",
    "\n",
    "    # pyplot.scatter(result[:, 0], result[:, 1])\n",
    "    # words = list(model.wv.vocab)\n",
    "    # for i, word in enumerate(words):\n",
    "    #     pyplot.annotate(word.encode('utf-8'), xy=(result[i, 0], result[i, 1]))\n",
    "    # pyplot.show()\n",
    "\n",
    "    # 讀取每首歌的前10個tags\n",
    "\n",
    "    text = open('tags.txt').read()\n",
    "    print(text)\n",
    "    # 設定停用字(排除常用詞、無法代表特殊意義的字詞)\n",
    "    # stopwords = {}.fromkeys([\"書\"])\n",
    "    # 產生文字雲\n",
    "    wc = WordCloud(font_path=\"NotoSerifCJKtc-Black.otf\", #設置字體\n",
    "               background_color=\"white\", #背景顏色\n",
    "               max_words = 2000 ,)      #停用字詞\n",
    "    wc.generate(text)\n",
    "    # 視覺化呈現\n",
    "    plt.imshow(wc)\n",
    "    plt.axis(\"off\")\n",
    "    # plt.figure(figsize=(10,6), dpi = 100)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    #parser = ArgumentParser()\n",
    "    #parser.add_argument(\"-n\", \"--novel\", default=1,type=int)\n",
    "    #parser.add_argument(\"-m\", \"--mode\", default='train', type=str)\n",
    "    #parser.add_argument(\"-t\", \"--topn\", default=10, type=int)\n",
    "    #args = parser.parse_args()\n",
    "    #main()\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: ['柯景騰', '沈佳儀', '阿和', '許博淳', '廖英宏'], 2: ['阿拓', '思螢', '老板娘', '阿不思']}\n"
     ]
    }
   ],
   "source": [
    "'''角色取得'''\n",
    "\n",
    "character = {1: [], 2: []}\n",
    "\n",
    "for index in range(len(character)):\n",
    "    f = codecs.open('user_dict_{0}.bin'.format(index + 1), 'r', 'utf-8')\n",
    "    a = [item for item in f.readlines()]\n",
    "\n",
    "    roles = []\n",
    "    for i in range(len(a)):\n",
    "        role = ''\n",
    "        for j in range(len(a[i])):\n",
    "            if a[i][j] == ' ':\n",
    "                break\n",
    "            role = role + a[i][j]\n",
    "        roles.append(role)\n",
    "    character[index + 1] = roles\n",
    "    f.close\n",
    "\n",
    "\n",
    "print(character)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>柯景騰</th>\n",
       "      <th>沈佳儀</th>\n",
       "      <th>阿和</th>\n",
       "      <th>許博淳</th>\n",
       "      <th>廖英宏</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>廖英宏</th>\n",
       "      <td>9.006612002849578857e-02</td>\n",
       "      <td>8.727215975522994995e-02</td>\n",
       "      <td>4.625630006194114685e-02</td>\n",
       "      <td>1.164279207587242126e-01</td>\n",
       "      <td>0.000000000000000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>柯景騰</th>\n",
       "      <td>0.000000000000000000e+00</td>\n",
       "      <td>-1.266602575778961182e-01</td>\n",
       "      <td>-1.096525341272354126e-01</td>\n",
       "      <td>-6.924734264612197876e-02</td>\n",
       "      <td>9.006612002849578857e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>沈佳儀</th>\n",
       "      <td>-1.266602575778961182e-01</td>\n",
       "      <td>0.000000000000000000e+00</td>\n",
       "      <td>-1.938269101083278656e-02</td>\n",
       "      <td>8.850599825382232666e-02</td>\n",
       "      <td>8.727215975522994995e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>許博淳</th>\n",
       "      <td>-6.924734264612197876e-02</td>\n",
       "      <td>8.850599825382232666e-02</td>\n",
       "      <td>-1.539127379655838013e-01</td>\n",
       "      <td>0.000000000000000000e+00</td>\n",
       "      <td>1.164279207587242126e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>阿和</th>\n",
       "      <td>-1.096525341272354126e-01</td>\n",
       "      <td>-1.938269101083278656e-02</td>\n",
       "      <td>0.000000000000000000e+00</td>\n",
       "      <td>-1.539127379655838013e-01</td>\n",
       "      <td>4.625630006194114685e-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           柯景騰                        沈佳儀  \\\n",
       "廖英宏   9.006612002849578857e-02   8.727215975522994995e-02   \n",
       "柯景騰   0.000000000000000000e+00  -1.266602575778961182e-01   \n",
       "沈佳儀  -1.266602575778961182e-01   0.000000000000000000e+00   \n",
       "許博淳  -6.924734264612197876e-02   8.850599825382232666e-02   \n",
       "阿和   -1.096525341272354126e-01  -1.938269101083278656e-02   \n",
       "\n",
       "                            阿和                        許博淳  \\\n",
       "廖英宏   4.625630006194114685e-02   1.164279207587242126e-01   \n",
       "柯景騰  -1.096525341272354126e-01  -6.924734264612197876e-02   \n",
       "沈佳儀  -1.938269101083278656e-02   8.850599825382232666e-02   \n",
       "許博淳  -1.539127379655838013e-01   0.000000000000000000e+00   \n",
       "阿和    0.000000000000000000e+00  -1.539127379655838013e-01   \n",
       "\n",
       "                          廖英宏  \n",
       "廖英宏  0.000000000000000000e+00  \n",
       "柯景騰  9.006612002849578857e-02  \n",
       "沈佳儀  8.727215975522994995e-02  \n",
       "許博淳  1.164279207587242126e-01  \n",
       "阿和   4.625630006194114685e-02  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "mat = {1: {}, 2: {}}\n",
    "\n",
    "'''corelation matrix'''\n",
    "for index in range(len(mat)):\n",
    "    with open('matrix_{0}.csv'.format(index + 1), newline='') as csvfile:\n",
    "        rows = csv.reader(csvfile)\n",
    "        row = []\n",
    "        for i in rows:\n",
    "            row.append(i)\n",
    "            \n",
    "    for i in range(len(character[index + 1])):\n",
    "        mat[index + 1][character[index + 1][i]] = {}\n",
    "        for j in range(len(character[index + 1])):\n",
    "            mat[index + 1][character[index + 1][i]][character[index + 1][j]] = row[i][j]\n",
    "\n",
    "co_mat = pd.DataFrame.from_dict(mat[1])\n",
    "co_mat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>阿拓</th>\n",
       "      <th>思螢</th>\n",
       "      <th>老板娘</th>\n",
       "      <th>阿不思</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>思螢</th>\n",
       "      <td>5.788053199648857117e-02</td>\n",
       "      <td>0.000000000000000000e+00</td>\n",
       "      <td>4.774375259876251221e-02</td>\n",
       "      <td>-4.589994624257087708e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>老板娘</th>\n",
       "      <td>-4.693402349948883057e-02</td>\n",
       "      <td>4.774375259876251221e-02</td>\n",
       "      <td>0.000000000000000000e+00</td>\n",
       "      <td>2.362870723009109497e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>阿不思</th>\n",
       "      <td>7.771591842174530029e-02</td>\n",
       "      <td>-4.589994624257087708e-02</td>\n",
       "      <td>2.362870723009109497e-01</td>\n",
       "      <td>0.000000000000000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>阿拓</th>\n",
       "      <td>0.000000000000000000e+00</td>\n",
       "      <td>5.788053199648857117e-02</td>\n",
       "      <td>-4.693402349948883057e-02</td>\n",
       "      <td>7.771591842174530029e-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            阿拓                         思螢  \\\n",
       "思螢    5.788053199648857117e-02   0.000000000000000000e+00   \n",
       "老板娘  -4.693402349948883057e-02   4.774375259876251221e-02   \n",
       "阿不思   7.771591842174530029e-02  -4.589994624257087708e-02   \n",
       "阿拓    0.000000000000000000e+00   5.788053199648857117e-02   \n",
       "\n",
       "                           老板娘                        阿不思  \n",
       "思螢    4.774375259876251221e-02  -4.589994624257087708e-02  \n",
       "老板娘   0.000000000000000000e+00   2.362870723009109497e-01  \n",
       "阿不思   2.362870723009109497e-01   0.000000000000000000e+00  \n",
       "阿拓   -4.693402349948883057e-02   7.771591842174530029e-02  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "co_mat2 = pd.DataFrame.from_dict(mat[2])\n",
    "co_mat2.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
